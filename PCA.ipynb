{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 490 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                                               Non-Null Count  Dtype  \n",
      "---  ------                                                               --------------  -----  \n",
      " 0   per_capita_crime_rate                                                490 non-null    float64\n",
      " 1   proportion_of_residential_land_over_25000_sq.ft.                     490 non-null    float64\n",
      " 2   proportion_of_non-retail_business_acres_per_town                     490 non-null    float64\n",
      " 3   Charles_River_dummy_variable_(1_if_tract_bounds_river;_0_otherwise)  490 non-null    float64\n",
      " 4   nitric_oxides_concentration_(parts_per_10_million)                   490 non-null    float64\n",
      " 5   average_number_of_rooms_per_dwelling                                 490 non-null    float64\n",
      " 6   proportion_of_owner-occupied_units_built_prior_to_1940               490 non-null    float64\n",
      " 7   weighted_distances_to_five_Boston_employment_centres                 490 non-null    float64\n",
      " 8   index_of_accessibility_to_radial_highways                            490 non-null    float64\n",
      " 9   full-value_property-tax_rate_per_$10000                              490 non-null    float64\n",
      " 10  pupil-teacher_ratio_by_town                                          490 non-null    float64\n",
      " 11  1000(Bk _0.63)^2_where_Bk_is_the_proportion_of_blacks_by_town        490 non-null    float64\n",
      " 12  %_lower_status_population                                            490 non-null    float64\n",
      " 13  Median_House_Price                                                   490 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 57.4 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Housing.csv\")\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (ERROR IN PREDICTION: Preferred value: <10):  4.772467263566135\n"
     ]
    }
   ],
   "source": [
    "feature_cols = data.columns.values.tolist()[:-1]\n",
    "X = data[feature_cols]\n",
    "y = data[data.columns.values.tolist()[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# rmse\n",
    "print(\"RMSE (ERROR IN PREDICTION: Preferred value: <10): \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variance explained by 5 features is: 80.67\n",
      "RMSE (ERROR IN PREDICTION: Preferred value: <10):  4.810705153989695\n"
     ]
    }
   ],
   "source": [
    "# standardize x before applying pca\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "\n",
    "# Create PCA object \n",
    "# define number of components after reduction\n",
    "n_components=5\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and Apply dimensionality reduction on X\n",
    "# apply pca only on training data and then fit the same on testing and cv data\n",
    "X_train_pc = pca.fit_transform(X_train_std)\n",
    "\n",
    "# The amount of variance that each PC explains\n",
    "var = pca.explained_variance_ratio_\n",
    "# find total variance explained by the given number of components\n",
    "# take total number of components which can explain 99% variance\n",
    "total_variance = sum(var)\n",
    "print(\"Total variance explained by {0} features is: {1}\".format(n_components, round(total_variance*100, 2)))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pc, y_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_test_pc = pca.transform(X_test_std)\n",
    "y_pred = model.predict(X_test_pc)\n",
    "\n",
    "# rmse\n",
    "print(\"RMSE (ERROR IN PREDICTION: Preferred value: <10): \", np.sqrt(mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
